{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "from langchain.llms.bedrock import Bedrock\n",
    "\n",
    "#get the model ids from here\n",
    "#https://docs.aws.amazon.com/bedrock/latest/userguide/model-ids.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bedrock boto3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Here are some key facts about the English Premier League (EPL):\n",
      "\n",
      "- The EPL is the top level of the English football league system. It was formed in 1992 when clubs broke away from the Football League to take advantage of lucrative TV rights deals.\n",
      "\n",
      "- There are 20 clubs in the Premier League. During the course of a season, each club plays 38 matches against the other clubs (home and away). \n",
      "\n",
      "- At the end of the season, the club at the top of the table is crowned champion. The top teams also qualify for the UEFA Champions League. The bottom three teams are relegated to the lower Championship league.\n",
      "\n",
      "- Some of the biggest and most successful Premier League clubs include Manchester United, Liverpool, Chelsea, Arsenal, Manchester City and Tottenham Hotspur. \n",
      "\n",
      "- The EPL is one of the most popular sports leagues in the world. Matches are broadcast in over 200 countries to billions of viewers. \n",
      "\n",
      "- Top players from around the world are drawn to the Premier League given its profile and lucrative salaries. Some standout players currently include Mohamed Salah, Kevin De Bruyne, Harry Kane among others.\n",
      "\n",
      "- The record for most Premier League titles is 13 by Manchester United. Their manager Sir Alex Ferguson also holds the record for most Premier League manager wins. \n",
      "\n",
      "- The current Premier League champions are Manchester City. The most recent season was dominated by a close title race between City and Liverpool.\n",
      "\n",
      "Let me know if you need any other details about the Premier League!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import boto3\n",
    "import json\n",
    "\n",
    "bedrock = boto3.client(service_name='bedrock-runtime', region_name='us-east-1')\n",
    "\n",
    "modelId = 'anthropic.claude-v2'\n",
    "accept = 'application/json'\n",
    "contentType = 'application/json'\n",
    "body = json.dumps({\n",
    "    \"prompt\": \"Human: Tell me about the English Premier League. Assistant:\",\n",
    "    \"max_tokens_to_sample\": 500\n",
    "})\n",
    "\n",
    "response = bedrock.invoke_model(body=body, modelId=modelId, accept=accept, contentType=contentType)\n",
    "response_body = json.loads(response.get('body').read())\n",
    "\n",
    "print(response_body.get('completion'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bedrock + LangChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Here are some key facts about Real Madrid:\n",
      "\n",
      "- Real Madrid is a professional football club based in Madrid, Spain. They play in La Liga, the top tier of Spanish football.\n",
      "\n",
      "- Founded in 1902, Real Madrid is one of the most successful and valuable sports teams in the world. They have won a record 13 UEFA Champions League titles and 34 La Liga titles, among many other trophies.\n",
      "\n",
      "- Real Madrid plays its home matches at the Santiago Bernabéu Stadium, which has a capacity of over 80,000 spectators. The stadium was built in 1947 and is located in the heart of Madrid.\n",
      "\n",
      "- Some of the greatest players in football history have played for Real Madrid, such as Alfredo Di Stéfano, Ferenc Puskás, Zinedine Zidane, Ronaldo Nazário, and Cristiano Ronaldo. \n",
      "\n",
      "- Current stars of the team include Karim Benzema, Luka Modric, Toni Kroos, and goalkeeper Thibaut Courtois. The team is coached by Carlo Ancelotti.\n",
      "\n",
      "- Real Madrid has a worldwide fanbase and is estimated to have over 200 million fans. They are one of the world's richest and most valuable sports clubs, with estimated revenues over $700 million annually.\n",
      "\n",
      "- The club is owned by its members (socios) and is run by president Florentino Pérez. Their biggest rivals are FC Barcelona, with whom they contest the famous El Clásico match.\n"
     ]
    }
   ],
   "source": [
    "from langchain.llms.bedrock import Bedrock\n",
    "\n",
    "llm = Bedrock( #create a bedrock llm client\n",
    "    region_name = 'us-east-1',\n",
    "    model_id = 'anthropic.claude-v2',\n",
    "    model_kwargs= {\"max_tokens_to_sample\": 500}\n",
    ")\n",
    "prompt = \"Tell me about Real Madrid\"\n",
    "response_text = llm.predict(prompt) #return a response to the prompt\n",
    "print(response_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Vermont does not have any cities. It is the second least populated state in the United States. The largest town in Vermont is\n"
     ]
    }
   ],
   "source": [
    "prompt = \"What is the largest city in Vermont?\"\n",
    "response_text = llm.predict(prompt) #return a response to the prompt\n",
    "print(response_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inference parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_inference_parameters(model): #return a default set of parameters based on the model's provider\n",
    "    bedrock_model_provider = model.split('.')[0] #grab the model provider from the first part of the model id\n",
    "    \n",
    "    if (bedrock_model_provider == 'anthropic'): #Anthropic model\n",
    "        return { #anthropic\n",
    "            \"max_tokens_to_sample\": 512,\n",
    "            \"temperature\": 0, \n",
    "            \"top_k\": 250, \n",
    "            \"top_p\": 1, \n",
    "            \"stop_sequences\": [\"\\n\\nHuman:\"] \n",
    "           }\n",
    "    \n",
    "    elif (bedrock_model_provider == 'ai21'): #AI21\n",
    "        return { #AI21\n",
    "            \"maxTokens\": 512, \n",
    "            \"temperature\": 0, \n",
    "            \"topP\": 0.5, \n",
    "            \"stopSequences\": [], \n",
    "            \"countPenalty\": {\"scale\": 0 }, \n",
    "            \"presencePenalty\": {\"scale\": 0 }, \n",
    "            \"frequencyPenalty\": {\"scale\": 0 } \n",
    "           }\n",
    "    \n",
    "    elif (bedrock_model_provider == 'cohere'): #COHERE\n",
    "        return {\n",
    "            \"max_tokens\": 512,\n",
    "            \"temperature\": 0,\n",
    "            \"p\": 0.01,\n",
    "            \"k\": 0,\n",
    "            \"stop_sequences\": [],\n",
    "            \"return_likelihoods\": \"NONE\"\n",
    "        }\n",
    "    \n",
    "    elif (bedrock_model_provider == 'meta'): #META\n",
    "        return {\n",
    "            \"temperature\": 0,\n",
    "            \"top_p\": 0.9,\n",
    "            \"max_gen_len\": 512\n",
    "        }\n",
    "\n",
    "    else: #Amazon\n",
    "        #For the LangChain Bedrock implementation, these parameters will be added to the \n",
    "        #textGenerationConfig item that LangChain creates for us\n",
    "        return { \n",
    "            \"maxTokenCount\": 512, \n",
    "            \"stopSequences\": [], \n",
    "            \"temperature\": 0, \n",
    "            \"topP\": 0.9 \n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Build the function to call Bedrock with the appropriate inference parameters for the model.\n",
    "def get_text_response(model, input_content): #text-to-text client function\n",
    "    \n",
    "    model_kwargs = get_inference_parameters(model) #get the default parameters based on the selected model\n",
    "    \n",
    "    llm = Bedrock( #create a Bedrock llm client\n",
    "        credentials_profile_name=os.environ.get(\"BWB_PROFILE_NAME\"), #sets the profile name to use for AWS credentials (if not the default)\n",
    "        region_name='us-east-1', #sets the region name (if not the default)\n",
    "        endpoint_url=os.environ.get(\"BWB_ENDPOINT_URL\"), #sets the endpoint URL (if necessary)\n",
    "        model_id=model, #use the requested model\n",
    "        model_kwargs = model_kwargs\n",
    "    )\n",
    "    \n",
    "    return llm.predict(input_content) #return a response to the prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " The largest city in Vermont is Burlington.\n"
     ]
    }
   ],
   "source": [
    "prompt = \"What is the largest city in Vermont?\"\n",
    "response_text = get_text_response('anthropic.claude-v2',prompt)\n",
    "print(response_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Temperature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Build the function to call Bedrock with the appropriate inference parameters for the model.\n",
    "def get_text_response(model, input_content, temperature): #text-to-text client function\n",
    "    model_kwargs = get_inference_parameters(model) #get the default parameters based on the selected model\n",
    "    model_kwargs['temperature'] = temperature if 'temperature' in model_kwargs else model_kwargs.get('temperature')\n",
    "\n",
    "    llm = Bedrock( #create a Bedrock llm client\n",
    "        region_name='us-east-1', #sets the region name (if not the default)\n",
    "        model_id=model, #use the requested model\n",
    "        model_kwargs = model_kwargs\n",
    "    )\n",
    "    \n",
    "    return llm.predict(input_content) #return a response to the prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Leaving home\n",
      "Heading out on a journey\n",
      "Destination unknown\n",
      "\n",
      "Leaving home\n",
      "Heading out on a journey\n",
      "Destination unknown\n"
     ]
    }
   ],
   "source": [
    "prompt = \"Write a haiku about a long journey:\"\n",
    "response_text = get_text_response('ai21.j2-ultra-v1',prompt, 0.5)\n",
    "print(response_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prompting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import (\n",
    "    ChatPromptTemplate,\n",
    "    FewShotChatMessagePromptTemplate,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Human: Messi\n",
      "AI: Barcelona\n",
      "Human: Figo\n",
      "AI: Real Madrid\n"
     ]
    }
   ],
   "source": [
    "examples = [\n",
    "    {\"input\": \"Messi\", \"output\": \"Barcelona\"},\n",
    "    {\"input\": \"Figo\", \"output\": \"Real Madrid\"},\n",
    "]\n",
    "example_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"human\", \"{input}\"),\n",
    "        (\"ai\", \"{output}\"),\n",
    "    ]\n",
    ")\n",
    "few_shot_prompt = FewShotChatMessagePromptTemplate(\n",
    "    example_prompt=example_prompt,\n",
    "    examples=examples,\n",
    ")\n",
    "final_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", \"You respond with the most famous\\\n",
    "                    team a player belonged to. Just the team name\"),\n",
    "        few_shot_prompt,\n",
    "        (\"human\", \"{input}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(few_shot_prompt.format())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", \"You respond with the most famous\\\n",
    "                    team a player belonged to. Just the team name\"),\n",
    "        few_shot_prompt,\n",
    "        (\"human\", \"{input}\"),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'generations': [{'finish_reason': 'COMPLETE', 'id': 'cded2d40-46bd-4fac-bb9e-649f859ad963', 'text': ' Napoli'}], 'id': 'af716a91-3671-4758-8baf-a8de3b4536ab', 'prompt': 'System: You respond with the most famous team a player belonged to. Just the team name\\nHuman: Messi\\nAI: Barcelona\\nHuman: Figo\\nAI: Real Madrid\\nHuman: Maradona'}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "' Napoli'"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.llms.bedrock import Bedrock\n",
    "import json\n",
    "\n",
    "llm = Bedrock( #create a bedrock llm client\n",
    "    region_name = 'us-east-1',\n",
    "    model_id = 'cohere.command-text-v14',\n",
    "    model_kwargs={\"temperature\": 0}\n",
    ")\n",
    "chain = final_prompt | llm\n",
    "\n",
    "chain.invoke({\"input\": \"Maradona\"})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
