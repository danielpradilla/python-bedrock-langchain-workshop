{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import boto3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#initialize session\n",
    "session = boto3.Session(\n",
    "    profile_name=os.environ.get(\"BWB_PROFILE_NAME\")\n",
    ") #sets the profile name to use for AWS credentials\n",
    "\n",
    "bedrock = session.client(\n",
    "    service_name='bedrock-runtime', #creates a Bedrock client\n",
    "    region_name='us-east-1',\n",
    "    endpoint_url=os.environ.get(\"BWB_ENDPOINT_URL\")\n",
    ") \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_inference_parameters(model): #return a default set of parameters based on the model's provider\n",
    "    bedrock_model_provider = model.split('.')[0] #grab the model provider from the first part of the model id\n",
    "    \n",
    "    if (bedrock_model_provider == 'anthropic'): #Anthropic model\n",
    "        return { #anthropic\n",
    "            \"max_tokens_to_sample\": 512,\n",
    "            \"temperature\": 0, \n",
    "            \"top_k\": 250, \n",
    "            \"top_p\": 1, \n",
    "            \"stop_sequences\": [\"\\n\\nHuman:\"] \n",
    "           }\n",
    "    \n",
    "    elif (bedrock_model_provider == 'ai21'): #AI21\n",
    "        return { #AI21\n",
    "            \"maxTokens\": 512, \n",
    "            \"temperature\": 0, \n",
    "            \"topP\": 0.5, \n",
    "            \"stopSequences\": [], \n",
    "            \"countPenalty\": {\"scale\": 0 }, \n",
    "            \"presencePenalty\": {\"scale\": 0 }, \n",
    "            \"frequencyPenalty\": {\"scale\": 0 } \n",
    "           }\n",
    "    \n",
    "    elif (bedrock_model_provider == 'cohere'): #COHERE\n",
    "        return {\n",
    "            \"max_tokens\": 512,\n",
    "            \"temperature\": 0,\n",
    "            \"p\": 0.01,\n",
    "            \"k\": 0,\n",
    "            \"stop_sequences\": [],\n",
    "            \"return_likelihoods\": \"NONE\"\n",
    "        }\n",
    "    \n",
    "    elif (bedrock_model_provider == 'meta'): #META\n",
    "        return {\n",
    "            \"temperature\": 0,\n",
    "            \"top_p\": 0.9,\n",
    "            \"max_gen_len\": 512\n",
    "        }\n",
    "\n",
    "    else: #Amazon\n",
    "        #For the LangChain Bedrock implementation, these parameters will be added to the \n",
    "        #textGenerationConfig item that LangChain creates for us\n",
    "        return { \n",
    "            \"maxTokenCount\": 512, \n",
    "            \"stopSequences\": [], \n",
    "            \"temperature\": 0, \n",
    "            \"topP\": 0.9 \n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Streaming responses\n",
    "\n",
    "We use Bedrock's invoke_model_with_response_stream function to make the call to the streaming API endpoint.\n",
    "As response chunks are returned, this code extracts the chunk's text from the returned JSON and passes it to the provided callback method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#callback handler for streaming\n",
    "def chunk_handler(chunk):\n",
    "    print(chunk, end='')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_streaming_response(bedrock_model_id, prompt, streaming_callback):\n",
    "\n",
    "    model_kwargs = get_inference_parameters(bedrock_model_id) #get the default parameters based on the selected model\n",
    "    \n",
    "    model_kwargs['prompt'] = prompt\n",
    "\n",
    "    body = json.dumps(model_kwargs)\n",
    "\n",
    "    response = bedrock.invoke_model_with_response_stream(modelId=bedrock_model_id, body=body) #invoke the streaming method\n",
    "    stream = response.get('body')\n",
    "    if stream:\n",
    "        for event in stream: #process each event returned by the stream\n",
    "            chunk = event.get('chunk')\n",
    "            if chunk:\n",
    "                chunk_json = json.loads(chunk.get('bytes').decode())\n",
    "                streaming_callback(chunk_json[\"completion\"]) #pass the latest chunk's text to the callback method\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Here is a story about two puppies and two kittens who became best friends:\n",
      "\n",
      "Floppy and Scruffy were two energetic puppy brothers who loved to play all day long. They would chase each other around the yard, wrestle and tumble, and chew on toys together. One day, their family brought home two kittens named Mittens and Boots. At first, the puppies barked excitedly at the new kittens, which scared the little furballs. The kittens hissed at the puppies and tried to swat them away. \n",
      "\n",
      "After a few days, the puppies calmed down and tried to get the kittens to play. They brought over balls and squeaky toys as gifts, but the kittens just batted them away. Floppy and Scruffy were sad that the kittens didn't want to play. Their mom told them to give the kittens some time to get used to their new home. So the puppies played with each other while keeping an eye on the kittens from across the room.  \n",
      "\n",
      "Eventually, curiosity got the best of Mittens and Boots. They slowly crept up to the puppies while they were napping. The kittens reached out a paw and tapped the puppies, then jumped back. Floppy and Scruffy woke up and were thrilled to see the kittens up close! They wagged their tails gently which made the kittens less scared. \n",
      "\n",
      "From then on, the two puppies and two kittens became inseparable best friends. They chased balls together, played hide and seek, and even napped in a cozy pile. Every day was filled with new adventures and fun for the four furry friends. Their different personalities and silly antics made them the perfect match. The puppies loved having the kittens to play with, and the kittens loved having puppy protectors. Together, they enjoyed a wonderful friendship that lasted a lifetime."
     ]
    }
   ],
   "source": [
    "prompt = \"\\n\\nHuman:Tell me a story about two puppies and two kittens who became best friends\\n\\nAssistant:\"\n",
    "                \n",
    "get_streaming_response('anthropic.claude-v2', prompt, chunk_handler)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.callbacks.streaming_stdout import StreamingStdOutCallbackHandler\n",
    "from langchain.llms.bedrock import Bedrock"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_streaming_response(bedrock_model_id, prompt):\n",
    "\n",
    "    model_kwargs = get_inference_parameters(bedrock_model_id) #get the default parameters based on the selected model\n",
    "   \n",
    "    llm = Bedrock(\n",
    "        model_id=bedrock_model_id,\n",
    "        streaming=True,\n",
    "        callbacks=[StreamingStdOutCallbackHandler()],\n",
    "        model_kwargs=model_kwargs\n",
    "    )\n",
    "    \n",
    "    return llm.predict(prompt) #return a response to the prompt\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Here is a story about two puppies and two kittens who became best friends:\n",
      "\n",
      "Floppy and Scruffy were two energetic puppy brothers who loved to play all day long. They would chase each other around the yard, wrestle and tumble, and chew on sticks and bones. One day, their family brought home two kittens named Mittens and Boots. At first, the puppies barked excitedly at the new kittens, which scared the little furballs. The kittens hissed at the puppies and tried to swat them away with their paws. \n",
      "\n",
      "After a few days, the puppies and kittens got used to each other. Floppy brought over a ball to Mittens, who hesitantly batted it back to him. Scruffy curled up next to Boots for a nap in a sunny patch of grass. The kittens realized the puppies just wanted to be friends. Soon, the four pets were inseparable. They played tag in the backyard, cuddled up for naps together, and shared meals side by side. At night, the puppies and kittens would snuggle up in a big pile of furry friends. Floppy, Scruffy, Mittens and Boots became the best of friends and brought joy and laughter to their family."
     ]
    },
    {
     "data": {
      "text/plain": [
       "' Here is a story about two puppies and two kittens who became best friends:\\n\\nFloppy and Scruffy were two energetic puppy brothers who loved to play all day long. They would chase each other around the yard, wrestle and tumble, and chew on sticks and bones. One day, their family brought home two kittens named Mittens and Boots. At first, the puppies barked excitedly at the new kittens, which scared the little furballs. The kittens hissed at the puppies and tried to swat them away with their paws. \\n\\nAfter a few days, the puppies and kittens got used to each other. Floppy brought over a ball to Mittens, who hesitantly batted it back to him. Scruffy curled up next to Boots for a nap in a sunny patch of grass. The kittens realized the puppies just wanted to be friends. Soon, the four pets were inseparable. They played tag in the backyard, cuddled up for naps together, and shared meals side by side. At night, the puppies and kittens would snuggle up in a big pile of furry friends. Floppy, Scruffy, Mittens and Boots became the best of friends and brought joy and laughter to their family.'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt = \"\\n\\nHuman:Tell me a story about two puppies and two kittens who became best friends\\n\\nAssistant:\"\n",
    "                \n",
    "get_streaming_response('anthropic.claude-v2', prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Custom callback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.callbacks.base import BaseCallbackHandler\n",
    "\n",
    "class SimpleCallback(BaseCallbackHandler):\n",
    "\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def on_llm_start(self, serialized, prompts, **kwargs):\n",
    "        print(f\"LLM Start triggered with prompt - {prompts}\")\n",
    "\n",
    "    def on_llm_new_token(self, token: str, **kwargs) -> None:\n",
    "        print(token, end='--')\n",
    "    \n",
    "    def on_llm_end(self, *args, **kwargs) -> None:\n",
    "        print(\"\\nI'm done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_streaming_response(bedrock_model_id, prompt):\n",
    "\n",
    "    model_kwargs = get_inference_parameters(bedrock_model_id) #get the default parameters based on the selected model\n",
    "   \n",
    "    llm = Bedrock(\n",
    "        model_id=bedrock_model_id,\n",
    "        streaming=True,\n",
    "        callbacks=[SimpleCallback()],\n",
    "        model_kwargs=model_kwargs\n",
    "    )\n",
    "    \n",
    "    return llm.predict(prompt) #return a response to the prompt\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LLM Start triggered with prompt - ['\\n\\nHuman:Tell me a one-paragraph joke\\n\\nAssistant:']\n",
      " Here--'s-- a-- one-- paragraph-- joke--:--\n",
      "\n",
      "A man-- walked-- into-- a-- bar-- and-- ordered-- a-- beer--.-- As-- the-- bartender-- went-- to-- get-- it--,-- he-- noticed-- a-- gor--illa-- sitting-- at-- the-- end-- of-- the-- bar--.-- He-- didn--'t-- think-- much-- of-- it-- and-- brought-- the-- man-- his-- drink--.-- A-- little-- while-- later--,-- the-- man-- ordered-- another-- beer-- and-- the-- bartender-- noticed-- the-- gor--illa-- was-- still-- sitting-- there--.-- The-- man-- ordered-- another-- beer--,-- and-- another--,-- and-- another--.-- By-- this-- point--,-- the-- bartender-- was-- getting-- curious-- about-- the-- gor--illa-- just-- sitting-- there--.-- So-- he-- finally-- asked-- the-- man--,-- \"--Hey--,-- what--'s-- with-- the-- gor--illa--?-- He--'s-- been-- sitting-- there-- this-- whole-- time--.\"-- The-- man-- replied--,-- \"--Oh-- him--?-- That--'s-- my-- pet-- gor--illa--.-- His-- name-- is-- Mickey--.-- I--'ll-- prove-- it-- to-- you--.\"-- He-- turned-- to-- the-- gor--illa-- and-- said--,-- \"--Mic--key--,-- go-- get-- my-- wallet-- and-- pay-- the-- nice-- man--.\"-- The-- gor--illa-- got-- up--,-- walked-- over-- to-- the-- man--'s-- jacket--,-- took-- out-- his-- wallet--,-- pulled-- out-- the-- cash-- to-- cover-- the-- bill-- and-- some-- tip--,-- handed-- it-- to-- the-- bartender--,-- and-- then-- sat-- back-- down--.-- The-- bartender-- just-- stood-- there-- stunned-- and-- said--,-- \"--Wow--,-- that--'s-- amazing--!-- Where-- did-- you-- get-- a-- trained-- gor--illa-- like-- that--?\"-- The-- man-- replied--,-- \"--I-- found-- him-- in-- Africa--.-- There-- was-- a-- whole-- bunch-- of-- them-- being-- trained-- to-- do-- different-- jobs--.-- You-- wouldn--'t-- believe-- the-- kind-- of-- gor--illas-- you-- can-- get-- for-- $--500-- these-- days--!\"----\n",
      "I'm done!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "' Here\\'s a one paragraph joke:\\n\\nA man walked into a bar and ordered a beer. As the bartender went to get it, he noticed a gorilla sitting at the end of the bar. He didn\\'t think much of it and brought the man his drink. A little while later, the man ordered another beer and the bartender noticed the gorilla was still sitting there. The man ordered another beer, and another, and another. By this point, the bartender was getting curious about the gorilla just sitting there. So he finally asked the man, \"Hey, what\\'s with the gorilla? He\\'s been sitting there this whole time.\" The man replied, \"Oh him? That\\'s my pet gorilla. His name is Mickey. I\\'ll prove it to you.\" He turned to the gorilla and said, \"Mickey, go get my wallet and pay the nice man.\" The gorilla got up, walked over to the man\\'s jacket, took out his wallet, pulled out the cash to cover the bill and some tip, handed it to the bartender, and then sat back down. The bartender just stood there stunned and said, \"Wow, that\\'s amazing! Where did you get a trained gorilla like that?\" The man replied, \"I found him in Africa. There was a whole bunch of them being trained to do different jobs. You wouldn\\'t believe the kind of gorillas you can get for $500 these days!\"'"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt = \"\\n\\nHuman:Tell me a one-paragraph joke\\n\\nAssistant:\"\n",
    "                \n",
    "get_streaming_response('anthropic.claude-v2', prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
